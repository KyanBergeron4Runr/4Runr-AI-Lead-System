#!/usr/bin/env python3
"""
Test Comprehensive Production Logging

This script demonstrates the complete production logging system by running
real system operations and showing the captured training data.
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

def test_comprehensive_production_logging():
    """Test comprehensive production logging with multiple system components"""
    print("ğŸ­ Testing COMPREHENSIVE Production Logging")
    print("=" * 60)
    print("Running multiple system components to generate real training data...")
    print()
    
    # Test 1: Run SerpAPI scraping (already working)
    print("ğŸ” Test 1: SerpAPI Scraping Operations")
    print("-" * 40)
    
    try:
        from scraper.serpapi_linkedin_scraper import SerpAPILinkedInScraper
        
        print("ğŸ“Š Running real SerpAPI scraping...")
        scraper = SerpAPILinkedInScraper()
        leads = scraper.search_montreal_ceos_with_serpapi(max_results=2)
        
        print(f"âœ… SerpAPI scraping completed: {len(leads)} leads found")
        if leads:
            for i, lead in enumerate(leads[:2], 1):
                print(f"   {i}. {lead.get('name', 'Unknown')} - {lead.get('title', 'Unknown')}")
        
    except Exception as e:
        print(f"âš ï¸ SerpAPI test skipped: {e}")
    
    print()
    
    # Test 2: Run real enrichment operations
    print("ğŸ” Test 2: Real Lead Enrichment")
    print("-" * 40)
    
    try:
        sys.path.append('shared')
        from daily_enricher_agent import StealthEnricherAgent
        
        # Create real leads to enrich
        test_leads = [
            {
                'name': 'Alexandre Taillefer',
                'company': 'Hexo Corp',
                'record_id': 'real_test_001'
            },
            {
                'name': 'Jean-FranÃ§ois Baril',
                'company': 'Sigma Energy Storage',
                'record_id': 'real_test_002'
            }
        ]
        
        enricher = StealthEnricherAgent()
        
        for lead in test_leads:
            print(f"ğŸ“Š Enriching: {lead['name']} at {lead['company']}")
            result = enricher.enrich_lead_stealth(lead)
            
            print(f"   ğŸ“§ Email: {result.get('primary_email', 'None found')}")
            print(f"   ğŸ¯ Confidence: {result.get('confidence', 'None')}")
            print(f"   ğŸ”§ Methods: {', '.join(result.get('methods', []))}")
            print()
        
        print("âœ… Real enrichment operations completed")
        
    except Exception as e:
        print(f"âš ï¸ Enrichment test error: {e}")
    
    print()
    
    # Test 3: Check production logs generated
    print("ğŸ“‹ Test 3: Production Log Analysis")
    print("-" * 40)
    
    log_dir = Path("production_logs")
    if log_dir.exists():
        total_logs = 0
        log_summary = {}
        
        for subdir in log_dir.iterdir():
            if subdir.is_dir():
                log_files = list(subdir.glob("*.json"))
                if log_files:
                    count = len(log_files)
                    total_logs += count
                    log_summary[subdir.name] = count
                    
                    print(f"ğŸ“ {subdir.name}: {count} production logs")
                    
                    # Show latest log details
                    latest_log = max(log_files, key=lambda x: x.stat().st_mtime)
                    try:
                        with open(latest_log, 'r') as f:
                            log_data = json.load(f)
                        
                        print(f"   ğŸ“„ Latest: {latest_log.name}")
                        print(f"   ğŸ·ï¸ Training Labels: {len(log_data.get('training_labels', {}))}")
                        print(f"   ğŸ• Timestamp: {log_data.get('timestamp', 'Unknown')[:19]}")
                        
                        # Show training labels
                        labels = log_data.get('training_labels', {})
                        if labels:
                            print(f"   ğŸ“Š Labels: {', '.join([f'{k}={v}' for k, v in list(labels.items())[:3]])}")
                        
                    except Exception as e:
                        print(f"   âš ï¸ Could not read log: {e}")
                    
                    print()
        
        print(f"ğŸ“Š Total Production Logs: {total_logs}")
        print(f"ğŸ“ˆ Log Distribution: {log_summary}")
        
        if total_logs > 0:
            print(f"\nâœ… REAL production data successfully captured!")
            print(f"ğŸ¯ This data is from actual system operations")
            print(f"ğŸ¤– Ready for ML training and system optimization")
        else:
            print("ğŸ“­ No production logs found")
    else:
        print("ğŸ“ No production logs directory found")
    
    print()
    
    # Test 4: Create comprehensive training dataset
    print("ğŸ¤– Test 4: Training Dataset Creation")
    print("-" * 40)
    
    try:
        from shared.production_logger import production_logger
        
        print("ğŸ“Š Creating comprehensive training dataset...")
        dataset_path = production_logger.create_training_dataset()
        
        if Path(dataset_path).exists():
            with open(dataset_path, 'r') as f:
                dataset = json.load(f)
            
            info = dataset.get('dataset_info', {})
            records = dataset.get('training_records', [])
            
            print(f"âœ… Training dataset created: {Path(dataset_path).name}")
            print(f"   ğŸ“Š Total Records: {info.get('total_records', 0)}")
            print(f"   ğŸ·ï¸ Data Types: {len(info.get('data_types', []))}")
            print(f"   ğŸ“… Created: {info.get('created_at', 'Unknown')[:19]}")
            
            # Analyze record types and training labels
            record_types = {}
            all_labels = set()
            
            for record in records:
                log_type = record.get('log_type', 'unknown')
                record_types[log_type] = record_types.get(log_type, 0) + 1
                
                labels = record.get('training_labels', {})
                all_labels.update(labels.keys())
            
            print(f"   ğŸ“‹ Record Types: {dict(record_types)}")
            print(f"   ğŸ·ï¸ Training Labels: {len(all_labels)} unique labels")
            print(f"   ğŸ¯ Sample Labels: {', '.join(list(all_labels)[:5])}")
            
            print(f"\nğŸ‰ Training dataset ready for ML training!")
            print(f"ğŸ“ˆ Data quality: Production-grade with real operational context")
            
        else:
            print("âš ï¸ No training dataset created")
            
    except Exception as e:
        print(f"âš ï¸ Training dataset creation failed: {e}")
    
    print()
    print("ğŸ­ COMPREHENSIVE PRODUCTION LOGGING TEST COMPLETE")
    print("=" * 60)
    print("âœ… System is capturing REAL operational data for training")
    print("ğŸ¤– All future operations will contribute to training dataset")
    print("ğŸ“ˆ Data is production-grade and ready for ML model development")

if __name__ == "__main__":
    test_comprehensive_production_logging()